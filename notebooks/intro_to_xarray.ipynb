{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3450a97-23a8-4399-a39b-8600d8161615",
   "metadata": {},
   "source": [
    "# Intro to Xarray\n",
    "Here I'll demonstrate how Xarray can help simplify data processing of our orbital data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad421730-a892-4187-a51c-a3d3099188e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da67efe-cc4e-44d1-9f2d-dc68b52d3a6c",
   "metadata": {},
   "source": [
    "First we need to get get the files we want to load in. Rather than hard coding this in, I will use `glob` to extract the names of all of the input files contained in my data directory. You can think of this construct as an example of the *declarative programming* paradigm, because we are starting from our goal (get a sorted list of files in the data directory with names that end with `-XV.csv`) rather than explicitly writing out the steps needed to achieve the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d855d-ad58-4989-a1ad-8397e83b8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.join(os.pardir,\"data\")\n",
    "datafiles = glob.glob(os.path.join(datadir, \"*-XV.csv\"))\n",
    "datafiles.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ae296-00ed-426c-a98d-31f995c44a7f",
   "metadata": {},
   "source": [
    "Next I'll read in each of the files in the list. Xarray does not have a native way to direclty read in CSV files. [The Xarray documentation recommends using Pandas as an intermediate for processing CSV files.](https://docs.xarray.dev/en/stable/user-guide/io.html#csv-and-other-formats-supported-by-pandas) So we'll use the Pandas `read_csv` method to read each file in as a Pandas DataFrame and then convert the DataFrame to an Xarray Dataset. \n",
    "\n",
    "Before doing this for all of the files, let's start with a single one so we can follow each of the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbece222-8631-4b6c-ac2e-b739b83c18e0",
   "metadata": {},
   "source": [
    "### The data format.\n",
    "First, let's take a look at what the input data looks like so we know how best to go about reading it in. Let's start with the first file in our input file list. I'll print the first three lines so you can see how it is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35718632-9d57-41a6-a0f1-b809568ea318",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"File name: {datafiles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f14508-d80f-49b8-9017-06f5ef203105",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datafiles[0], 'r') as f:\n",
    "    [print(f\"Line {line_num+1}: {next(f)}\") for line_num in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09de41-49fb-4e64-a391-a75b8ae58a99",
   "metadata": {},
   "source": [
    "### Reading into a Pandas DataFrame\n",
    "The data is comma-delimited, and with a header as the first line. This format is basically what Pandas expects as a default, making our call to `read_csv` relatively straight-forward. Let's see what it looks like when we read this in using the default arguments to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed8308-8eb2-4b6f-a89d-90d5133f5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafiles[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b8b8db-f307-4f2b-b0e0-3d5fb6265a97",
   "metadata": {},
   "source": [
    "### Converting a Pandas DataFrame into an Xarray Dataset\n",
    "As you can see, Pandas has read this data in and labeled each row by its header value. Let's see what it looks like when we convert this to an Xarray Dataset. We'll use the built-in Pandas method `to_xarray` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1b105-77eb-4778-bd0b-a6d2c9834a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.to_xarray()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edac585-5199-4d21-9f16-9f478b3c7783",
   "metadata": {},
   "source": [
    "### Using a column of the input data as an index.\n",
    "This is pretty good, but notice how it has generated both a *dimension* and a *coordinate* called `index`. When a dimension and coordinate are linked in an Xarray object, it is called a *dimension coordinate* and is printed in bold in the Notebook view. This was automatically generated from the Pandas DataFrame's index column. However, we know that each row of data represents a point in time, so the data really ought to be indexed by the time variable, `t`. \n",
    "\n",
    "We could attempt to do this now by converting the Dataset variable `t` into a dimension coordinate, but I think it would be cleaner to get this sorted while reading in the data to begin with, as it only requires a single additional argument to our `read_csv` call: `index_col`. This tells Pandas which column of data should be treated as the index. This is the 0th column in our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f852b-53f6-40b2-8ac1-7f8f5aaf73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafiles[0],index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e396ce-1fd1-436e-b6ec-210c686c40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.to_xarray()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194e3c8-c92e-4e70-9998-91db4b0763a8",
   "metadata": {},
   "source": [
    "With one argument early in our process, we now have our time values as the *dimension coordinate* of the Dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c9cd0-b56f-4a01-b700-6c6dd0ade46d",
   "metadata": {},
   "source": [
    "### Including metadata to give context to your data\n",
    "One of the advantages of Xarray is that it provides far more options to supply useful metadata to our data. By giving our dimenion coordinates a name, we can process our data using that name and \"natural\" values of that name, rather than by arbitrary index values. Another way that useful metadata can be supplied is via attributes. These are metadata that can be used to give our data more context, by, for instance, supplying units to the data variables.\n",
    "\n",
    "You can create any kind of attribute you want, but there are two that you should start with, as these are used by the Xarray plotting methods to automatically label your plots for you once we get to that stage. These are: `units` and `long_name`. Let's set those for each of our Data variables and our time coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f80d7-719a-4a34-b24d-f5aad4b50c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['t'] = ds['t'].assign_attrs(long_name='Time', units='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311778b-74d2-47b2-b799-944b056c9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = ['x','y','z']\n",
    "for c in cart:\n",
    "    r = f\"r{c}h\"\n",
    "    v = f\"v{c}h\"\n",
    "    ds[r] = ds[r].assign_attrs(long_name=f\"Heliocentric $r_{c}$\", units='AU')\n",
    "    ds[v] = ds[v].assign_attrs(long_name=f\"Heliocentric $v_{c}$\", units='AU/day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc563c-dfc7-40a5-baa8-0f76126217b5",
   "metadata": {},
   "source": [
    "To see how useful this is, let's plot one of the variables. Notice that it labeled our axes for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcec31d-effa-41e7-b6f8-bfb4e1585014",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['rxh'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab8e01-1db7-425c-a6f3-f846b7f75059",
   "metadata": {},
   "source": [
    "Including metadata like this very early in the pipeling can greatly help with being able to understand the data you are working with, and help communicate results with less ambiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14864413-fc27-4a9c-a339-dabe2470bd0b",
   "metadata": {},
   "source": [
    "### Merging multiple input data files into one Dataset\n",
    "Now that we've established the basics of our data pipeline on one file, now we'd like to do this on all our files. Before we proceed, let's write a simple function that does all of the intermediate steps that we just did above, so we can repeat this for all of our data. By separating the data analysis steps into its own function, it helps improve the readability of our script, as the individual steps will be separated from the loop that executes all the steps. I'll also include a step that extracts the planet name from the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d97715-e21e-477d-96af-6d5f53c1dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inputs(filename):\n",
    "    # Read in data file and convert to Xarray Dataset\n",
    "    df = pd.read_csv(filename,index_col=0)\n",
    "    ds = df.to_xarray()\n",
    "    \n",
    "    # Set units and long_name attributes\n",
    "    ds['t'] = ds['t'].assign_attrs(long_name='Time', units='day')\n",
    "    cart = ['x','y','z']\n",
    "    for c in cart:\n",
    "        r = f\"r{c}h\"\n",
    "        v = f\"v{c}h\"\n",
    "        ds[r] = ds[r].assign_attrs(long_name=f\"Heliocentric $r_{c}$\", units='AU')\n",
    "        ds[v] = ds[v].assign_attrs(long_name=f\"Heliocentric $v_{c}$\", units='AU/day')\n",
    "        \n",
    "    # Extract planet name and store it as a new variable value\n",
    "    name = filename.split(os.path.sep)[-1].split(\"-\")[0]\n",
    "    ds['name'] = [name]\n",
    "    ds['name'] = ds['name'].assign_attrs(long_name=\"Planet name\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf604b-5e9e-43ab-bead-1a55e399289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_data = []\n",
    "for f in datafiles:\n",
    "    planet_data.append(process_inputs(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55990702-d7b8-4e13-a5b0-febb8a687c1c",
   "metadata": {},
   "source": [
    "Now we have a list of Xarray Datasets, with each element of the list representing a planet. Let's see what one of these looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f7a57-b74e-4816-9ea5-74d3a35dfbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88577959-e1cd-42a2-9e5c-e7abc951f76c",
   "metadata": {},
   "source": [
    "We could stop here, but we'd be left with a list of different Datasets that were disconnected from each other. However, we know that they all share the same time coordinates and variables. Xarray is designed to deal with multidimensional data, and so we can combine the data together into a single Dataset and treat planet names as a dimension of the data.\n",
    "\n",
    "Notice that Xarray automatically converted our `name` variable into a dimension coordinate for us, given that each input file had a single value for this variable. This makes it super easy to combine together. [There are a number of ways of combining data, depending on what you start with and what your goal is.](https://docs.xarray.dev/en/stable/user-guide/combining.html) Because of the choices we made throughout our processing pipeline, we can easily combine the data using a simple call to the `concat` method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145a4df-4e42-48bc-b529-5c3965d32d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.concat(planet_data,dim='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fb159-235f-455b-844d-57eb3925ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf80a7-2051-4b36-ab9a-15372adf4cb8",
   "metadata": {},
   "source": [
    "### Processing the Dataset.\n",
    "Now that we've got our data into a useful format, we can start to do some processing on it. Because our Dataset is rich with context, we can do most of our processing in the declarative programming mode. For instance, suppose we want to compute the position and velocity magnitudes of our planet orbits. These can be done with single lines that are easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589ac56-0b4f-47ed-829b-095a308059f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['rhmag'] = np.sqrt(ds['rxh']**2 + ds['ryh']**2 + ds['rzh']**2)\n",
    "ds['vhmag'] = np.sqrt(ds['vxh']**2 + ds['vyh']**2 + ds['vzh']**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4d44c-a8d1-4afa-b8d9-00027031d442",
   "metadata": {},
   "source": [
    "Remember to add metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f9c28-8e9e-42bb-860d-2dac1afec61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['rhmag'] = ds['rhmag'].assign_attrs(long_name=\"Heliocentric $|\\mathbf{r}|$\", units=\"AU\")\n",
    "ds['vhmag'] = ds['vhmag'].assign_attrs(long_name=\"Heliocentric $|\\mathbf{v}|$\", units=\"AU/day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85656a-4211-4a4d-bab6-1f54cb9bc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['rhmag'].plot(hue=\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba1211-7f0c-4ee9-9b10-05a86d0f1e4d",
   "metadata": {},
   "source": [
    "We can also add new variables to the Dataset by keeping in mind that each variable is a DataArray, so you can create them using out of thigns like numpy arrays, lists, dictionaries, etc. Let's do this for planet mass. I'll use list comprehension to convert our MSun/Mpl dictionary into Mpl values, using the dictionary keys as our dimension coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05507c7-67a3-4393-8453-ce9067824fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSun_over_Mpl = {\n",
    "    'Mercury': 6023600.0,\n",
    "    'Venus': 408523.71,\n",
    "    'Earth': 328900.56,\n",
    "    'Mars': 3098708.,\n",
    "    'Jupiter': 1047.3486,\n",
    "    'Saturn': 3497.898,\n",
    "    'Uranus': 22902.98,\n",
    "    'Neptune': 19412.24,\n",
    "    'Pluto': 1.35e8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243aec4-8184-49b1-80e5-629afcbf8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['mass'] = xr.DataArray(data=[1.0/v for k,v in MSun_over_Mpl.items()], \n",
    "             coords={\"name\" : [k for k in MSun_over_Mpl]},\n",
    "             attrs={\"long_name\" : \"Mass of planet\", \"units\" : \"$M_{sun}$\"},\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc2925-fd84-481d-90d0-e92f1a9cd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3476215-dc97-4d27-905c-eafc8ce75657",
   "metadata": {},
   "source": [
    "We can also compute the gravitational parameter value for each body that we can use for computing orbital elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b8485-2713-471d-9f5e-bb2283b7816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['mu'] = 1.0 + ds['mass']\n",
    "ds['mu'] = ds['mu'].assign_attrs(long_name=\"Gravitational parameter $\\mu$\", units=\"$M_{sun}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e3b87-3e13-4356-b6bc-f14a6e00abe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
